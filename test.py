import cv2
import mediapipe as mp
import time
import numpy as np
import threading
import sounddevice as sd
import librosa
import random
import asyncio
import bhaptics_python as bh # Î§ÏÎ®ÏƒÎ· Ï„Î¿Ï… SDK 2

# ================================================================================================
# Audio Engine & Globals (Î Î±ÏÎ±Î¼Î­Î½Î¿Ï…Î½ Î¯Î´Î¹Î±)
# ================================================================================================
audio, sr = librosa.load("music.mp3", sr=None, mono=True)
audio_lock = threading.Lock()
music_speed, music_playing, current_volume, music_pitch = 1.0, False, 50.0, 0
challenge_active, current_challenge, challenge_player, challenge_end_time = False, None, None, 0.0
scores = [0, 0]
prev_volume, prev_speed = 50.0, 1.0
original_audio = audio.copy()
audio_buffer = original_audio.copy()
audio_position = 0

# ================================================================================================
# Haptics Manager (SDK 2 Implementation)
# ================================================================================================
class HapticManager:
    def __init__(self):
        self.connected = False
        # Î£Ï„Î¿ SDK 2 Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ¼Îµ Ï„Î¿ App ID ÎºÎ±Î¹ Ï„Î¿ API Key Î±Ï€ÏŒ Ï„Î¿ bHaptics Portal
        self.app_id = "YOUR_APP_ID" 
        self.api_key = "YOUR_API_KEY"
        
    def connect(self):
        """Î‘ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· ÏƒÏÎ½Î´ÎµÏƒÎ·Ï‚ SDK 2"""
        try:
            # Î¤Î¿ SDK 2 Î±Ï€Î±Î¹Ï„ÎµÎ¯ ÎµÎ³Î³ÏÎ±Ï†Î® Ï„Î·Ï‚ ÎµÏ†Î±ÏÎ¼Î¿Î³Î®Ï‚
            bh.initialize(self.app_id, self.api_key)
            time.sleep(2)
            self.connected = True
            print("âœ… bHaptics SDK 2 Connected")
        except Exception as e:
            print(f"âŒ SDK 2 Connection Error: {e}")

    def play_dot(self, key, x, y, intensity):
        """Î‘Î½Ï„Î¯ÏƒÏ„Î¿Î¹Ï‡Î¿ Ï„Î¿Ï… submit_dot ÏƒÏ„Î¿ SDK 2"""
        if self.connected:
            # Î£Ï„Î¿ SDK 2 Î· ÎµÎ½Ï„Î¿Î»Î® ÏƒÏ„Î­Î»Î½ÎµÎ¹ dots ÏƒÎµ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î± frame
            bh.submit_dot(key, "Front", [{"index": 10, "intensity": int(intensity)}], 100)

    def play_event(self, event_name):
        """Î— Ï€ÏÎ¿Ï„ÎµÎ¹Î½ÏŒÎ¼ÎµÎ½Î· Î¼Î­Î¸Î¿Î´Î¿Ï‚ Ï„Î¿Ï… SDK 2 Î¼Î­ÏƒÏ‰ Ï€ÏÎ¿-ÏƒÏ‡ÎµÎ´Î¹Î±ÏƒÎ¼Î­Î½Ï‰Î½ Events"""
        if self.connected:
            bh.submit_registered(event_name)

# 

# ================================================================================================
# Gesture & Audio Logic (Î ÏÎ¿ÏƒÎ±ÏÎ¼Î¿ÏƒÎ¼Î­Î½Î¿ Î³Î¹Î± SDK 2)
# ================================================================================================
def rebuild_audio():
    global audio_buffer, audio_position
    audio_out = librosa.effects.time_stretch(original_audio, rate=music_speed)
    if music_pitch != 0:
        audio_out = librosa.effects.pitch_shift(audio_out, sr=sr, n_steps=music_pitch)
    with audio_lock:
        audio_buffer = audio_out
        audio_position = 0

def audio_callback(outdata, frames, time_info, status):
    global audio_position
    if not music_playing:
        outdata.fill(0)
        return
    with audio_lock:
        indices = (np.arange(audio_position, audio_position + frames)) % len(audio_buffer)
        outdata[:, 0] = audio_buffer[indices] * (current_volume / 100.0)
        audio_position = (audio_position + frames) % len(audio_buffer)

# 

class GestureManager:
    def __init__(self):
        self.mp_hands = mp.solutions.hands
        self.hands = self.mp_hands.Hands(min_detection_confidence=0.7, max_num_hands=2)
        self.mp_draw = mp.solutions.drawing_utils

    def analyze(self, frame):
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        res = self.hands.process(rgb)
        if res.multi_hand_landmarks:
            return list(zip(res.multi_hand_landmarks, res.multi_handedness))
        return []

# ================================================================================================
# Main loop
# ================================================================================================
def main():
    global music_speed, current_volume, music_playing, music_pitch, challenge_active
    
    cap = cv2.VideoCapture(0)
    haptics = HapticManager()
    haptics.connect() # Î£ÏÎ½Î´ÎµÏƒÎ· SDK 2
    gestures = GestureManager()
    
    stream = sd.OutputStream(samplerate=sr, channels=1, callback=audio_callback)
    stream.start()

    print("ğŸµ Maestro SDK 2 System Started")

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret: break
        frame = cv2.flip(frame, 1)
        results = gestures.analyze(frame)

        if results:
            for hand_lms, handedness in results:
                label = handedness.classification[0].label
                # Î‘Î½Î¯Ï‡Î½ÎµÏ…ÏƒÎ· ÎºÎ¹Î½Î®ÏƒÎµÏ‰Î½ (Pinch, Fist ÎºÎ»Ï€.)
                # Î•Î´Ï ÎºÎ±Î»Î¿ÏÎ¼Îµ Ï„Î± haptics.play_dot(...)
                
                # Î Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î±: Î”ÏŒÎ½Î·ÏƒÎ· ÏƒÏ„Î¿ Pinch
                thumb, index = hand_lms.landmark[4], hand_lms.landmark[8]
                dist = np.sqrt((thumb.x - index.x)**2 + (thumb.y - index.y)**2)
                if dist < 0.05:
                    haptics.play_dot("VestFront", 0.5, 0.5, 80)

        cv2.imshow("Maestro SDK 2", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'): break

    cap.release()
    cv2.destroyAllWindows()
    stream.stop()

if __name__ == "__main__":
    main()